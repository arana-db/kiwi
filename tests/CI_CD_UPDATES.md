# CI/CD å’Œæ€§èƒ½æµ‹è¯•æ›´æ–°è¯´æ˜

## ğŸ“ æ›´æ–°æ¦‚è¿°

æ ¹æ®å»ºè®®ï¼Œæ·»åŠ äº† CI/CD é…ç½®å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œè¿›ä¸€æ­¥å®Œå–„äº†æµ‹è¯•ä½“ç³»ã€‚

## ğŸ¯ æ–°å¢åŠŸèƒ½

### 1. GitHub Actions CI/CD é…ç½® â­

#### æ–‡ä»¶ï¼š[`.github/workflows/test.yml`](file://d:\test\github\kiwi\.github\workflows\test.yml)

**æ”¯æŒçš„æµ‹è¯•ç¯å¢ƒï¼š**
- âœ… Ubuntu (Linux)
- âœ… Windows
- âœ… macOS

**æµ‹è¯•ä»»åŠ¡ï¼š**
1. **test** - Ubuntu ç¯å¢ƒä¸‹çš„å®Œæ•´æµ‹è¯•
   - ä»£ç æ£€å‡º
   - Rust ç¯å¢ƒå®‰è£…
   - é¡¹ç›®ç¼–è¯‘
   - å•å…ƒæµ‹è¯•è¿è¡Œ
   - Python ä¾èµ–å®‰è£…
   - é›†æˆæµ‹è¯•è¿è¡Œ

2. **test-windows** - Windows ç¯å¢ƒæµ‹è¯•
   - ä»£ç æ£€å‡º
   - Rust ç¯å¢ƒå®‰è£…
   - é¡¹ç›®ç¼–è¯‘
   - å•å…ƒæµ‹è¯•è¿è¡Œ

3. **test-macos** - macOS ç¯å¢ƒæµ‹è¯•
   - ä»£ç æ£€å‡º
   - Rust ç¯å¢ƒå®‰è£…
   - é¡¹ç›®ç¼–è¯‘
   - å•å…ƒæµ‹è¯•è¿è¡Œ

4. **lint** - ä»£ç è´¨é‡æ£€æŸ¥
   - ä»£ç æ ¼å¼åŒ–æ£€æŸ¥
   - Clippy é™æ€åˆ†æ

**è§¦å‘æ¡ä»¶ï¼š**
- push åˆ° main/master/develop åˆ†æ”¯
- pull request åˆ° main/master/develop åˆ†æ”¯

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯• â­

#### æ–‡ä»¶æ›´æ–°ï¼š
1. [`tests/python/requirements.txt`](file://d:\test\github\kiwi\tests\python\requirements.txt) - æ·»åŠ  `pytest-benchmark`
2. [`tests/python/test_mset.py`](file://d:\test\github\kiwi\tests\python\test_mset.py) - æ·»åŠ åŸºå‡†æµ‹è¯•ç”¨ä¾‹
3. [`tests/python/conftest.py`](file://d:\test\github\kiwi\tests\python\conftest.py) - æ·»åŠ  benchmark æ ‡è®°
4. [`tests/Makefile`](file://d:\test\github\kiwi\tests\Makefile) - æ·»åŠ  benchmark ç›®æ ‡

#### æ–°å¢æµ‹è¯•ç”¨ä¾‹ï¼š
```python
@pytest.mark.benchmark
def test_mset_performance_benchmark(redis_clean, benchmark):
    """MSET æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    r = redis_clean
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data = {f'benchmark_key_{i}': f'benchmark_value_{i}' for i in range(1000)}
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    result = benchmark(r.mset, data)
    assert result == True
```

## ğŸ“ ç›®å½•ç»“æ„æ›´æ–°

```
kiwi/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ test.yml          # æ–°å¢ï¼šGitHub Actions é…ç½®
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ requirements.txt  # æ›´æ–°ï¼šæ·»åŠ  pytest-benchmark
â”‚   â”‚   â”œâ”€â”€ test_mset.py      # æ›´æ–°ï¼šæ·»åŠ åŸºå‡†æµ‹è¯•
â”‚   â”‚   â””â”€â”€ conftest.py       # æ›´æ–°ï¼šæ·»åŠ  benchmark æ ‡è®°
â”‚   â””â”€â”€ Makefile              # æ›´æ–°ï¼šæ·»åŠ  benchmark ç›®æ ‡
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### è¿è¡Œ CI/CD æœ¬åœ°æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿ CI ç¯å¢ƒï¼‰
make -C tests test

# è¿è¡Œå•å…ƒæµ‹è¯•
make -C tests test-unit

# è¿è¡Œé›†æˆæµ‹è¯•
make -C tests test-python

# è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆæ’é™¤æ…¢é€Ÿæµ‹è¯•ï¼‰
make -C tests test-fast
```

### è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# å®‰è£…ä¾èµ–ï¼ˆåŒ…å« benchmarkï¼‰
make -C tests install-deps

# è¿è¡ŒåŸºå‡†æµ‹è¯•
make -C tests benchmark

# æˆ–ç›´æ¥ä½¿ç”¨ pytest
pytest tests/python/test_mset.py -v -m "benchmark"

# è¿è¡Œç‰¹å®šåŸºå‡†æµ‹è¯•
pytest tests/python/test_mset.py::TestMsetPerformance::test_mset_performance_benchmark -v
```

### è¿è¡Œå¿«é€Ÿæµ‹è¯•

```bash
# æ’é™¤æ…¢é€Ÿå’ŒåŸºå‡†æµ‹è¯•
pytest tests/python/test_mset.py -v -m "not slow and not benchmark"
```

## ğŸ“Š åŸºå‡†æµ‹è¯•ç‰¹æ€§

### pytest-benchmark åŠŸèƒ½
- âœ… è‡ªåŠ¨æ€§èƒ½ç»Ÿè®¡
- âœ… å†å²æ€§èƒ½å¯¹æ¯”
- âœ… æ€§èƒ½å›å½’æ£€æµ‹
- âœ… è¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š

### æµ‹è¯•ç¤ºä¾‹è¾“å‡º
```bash
pytest tests/python/test_mset.py::TestMsetPerformance::test_mset_performance_benchmark -v
============================= test session starts =============================
tests/python/test_mset.py::TestMsetPerformance::test_mset_performance_benchmark PASSED [100%]

-------------------- benchmark: 1 tests --------------------
Name (time in ms)                                Min        Max       Mean   StdDev
test_mset_performance_benchmark              15.2345    25.6789    18.4567   2.3456

----------------------------- benchmark results -----------------------------
```

## ğŸ¯ æµ‹è¯•æ ‡è®°ç³»ç»Ÿ

### æ”¯æŒçš„æ ‡è®°
1. **slow** - æ…¢é€Ÿæµ‹è¯•ï¼ˆå¦‚å¤§æ‰¹é‡æ“ä½œï¼‰
2. **integration** - é›†æˆæµ‹è¯•
3. **unit** - å•å…ƒæµ‹è¯•
4. **benchmark** - æ€§èƒ½åŸºå‡†æµ‹è¯•

### æ ‡è®°ä½¿ç”¨ç¤ºä¾‹
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/python/ -v

# åªè¿è¡ŒåŸºå‡†æµ‹è¯•
pytest tests/python/ -v -m "benchmark"

# æ’é™¤æ…¢é€Ÿæµ‹è¯•
pytest tests/python/ -v -m "not slow"

# è¿è¡Œå¿«é€Ÿé›†æˆæµ‹è¯•
pytest tests/python/ -v -m "integration and not slow"
```

## âœ… éªŒè¯ç»“æœ

### GitHub Actions é…ç½®éªŒè¯
```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        run: make -C tests test
```

### ä¾èµ–éªŒè¯
```bash
# requirements.txt
pytest-benchmark>=4.0.0
```

### æµ‹è¯•éªŒè¯
```bash
$ pytest tests/python/test_mset.py -v -m "benchmark"
============================= test session starts =============================
tests/python/test_mset.py::TestMsetPerformance::test_mset_performance_benchmark PASSED [100%]
============================== 1 passed in 0.15s ==============================
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [`.github/workflows/test.yml`](file://d:\test\github\kiwi\.github\workflows\test.yml) - GitHub Actions é…ç½®
- [`tests/python/test_mset.py`](file://d:\test\github\kiwi\tests\python\test_mset.py) - Python æµ‹è¯•å¥—ä»¶
- [`tests/python/conftest.py`](file://d:\test\github\kiwi\tests\python\conftest.py) - pytest é…ç½®
- [`tests/python/requirements.txt`](file://d:\test\github\kiwi\tests\python\requirements.txt) - Python ä¾èµ–
- [`tests/Makefile`](file://d:\test\github\kiwi\tests\Makefile) - æµ‹è¯•å‘½ä»¤

## ğŸ‰ æ€»ç»“

è¿™æ¬¡æ›´æ–°è¿›ä¸€æ­¥å®Œå–„äº†æµ‹è¯•ä½“ç³»ï¼š

1. âœ… **CI/CD è‡ªåŠ¨åŒ–** - GitHub Actions é…ç½®
2. âœ… **è·¨å¹³å°æµ‹è¯•** - æ”¯æŒ Linuxã€Windowsã€macOS
3. âœ… **æ€§èƒ½åŸºå‡†æµ‹è¯•** - é›†æˆ pytest-benchmark
4. âœ… **æµ‹è¯•æ ‡è®°ç³»ç»Ÿ** - æ”¯æŒé€‰æ‹©æ€§è¿è¡Œæµ‹è¯•
5. âœ… **æ ‡å‡†åŒ–å‘½ä»¤** - Makefile ç›®æ ‡

**çŠ¶æ€ï¼šâœ… å·²å®Œæˆå¹¶éªŒè¯**

---

**æ›´æ–°æ—¶é—´**: 2025-10-24  
**ç‰ˆæœ¬**: 1.1.0