// Copyright (c) 2024-present, arana-db Community.  All rights reserved.
//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! State machine consistency verification and recovery mechanisms
//!
//! This module provides tools to verify that the applied state matches the Raft log
//! and implements recovery mechanisms for state machine inconsistencies.

use std::sync::Arc;
use std::time::{SystemTime, UNIX_EPOCH};

use rocksdb::IteratorMode;
use serde::{Deserialize, Serialize};
use tokio::sync::RwLock;

use crate::error::{RaftError, RaftResult};
use crate::placeholder_types::RocksdbEngine;
use crate::types::{LogIndex, NodeId};

/// Consistency check result
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ConsistencyStatus {
    /// State machine is consistent with the log
    Consistent,
    /// State machine is behind the log (missing applied entries)
    Behind {
        expected_index: LogIndex,
        actual_index: LogIndex,
    },
    /// State machine is ahead of the log (extra applied entries)
    Ahead {
        expected_index: LogIndex,
        actual_index: LogIndex,
    },
    /// State machine data is corrupted or inconsistent
    Corrupted { reason: String },
}

/// Consistency check metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsistencyMetadata {
    /// Last verified log index
    pub last_verified_index: LogIndex,
    /// Timestamp of last consistency check
    pub last_check_timestamp: u64,
    /// Number of consistency violations detected
    pub violation_count: u64,
    /// Last recovery timestamp
    pub last_recovery_timestamp: Option<u64>,
}

impl Default for ConsistencyMetadata {
    fn default() -> Self {
        Self {
            last_verified_index: 0,
            last_check_timestamp: 0,
            violation_count: 0,
            last_recovery_timestamp: None,
        }
    }
}

/// State machine consistency checker
pub struct ConsistencyChecker {
    /// Database engine for state verification
    engine: Arc<RocksdbEngine>,
    /// Consistency metadata
    metadata: Arc<RwLock<ConsistencyMetadata>>,
    /// Node ID for logging purposes
    node_id: NodeId,
}

impl ConsistencyChecker {
    /// Create a new consistency checker
    pub fn new(engine: Arc<RocksdbEngine>, node_id: NodeId) -> Self {
        Self {
            engine,
            metadata: Arc::new(RwLock::new(ConsistencyMetadata::default())),
            node_id,
        }
    }

    /// Verify state machine consistency against expected log index
    pub async fn verify_consistency(
        &self,
        expected_log_index: LogIndex,
    ) -> RaftResult<ConsistencyStatus> {
        let current_timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();

        // Get current applied index from state machine
        let actual_index = self.get_applied_index().await?;

        // Update metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.last_check_timestamp = current_timestamp;
            metadata.last_verified_index = expected_log_index;
        }

        // Compare indices
        let status = match actual_index.cmp(&expected_log_index) {
            std::cmp::Ordering::Equal => ConsistencyStatus::Consistent,
            std::cmp::Ordering::Less => ConsistencyStatus::Behind {
                expected_index: expected_log_index,
                actual_index,
            },
            std::cmp::Ordering::Greater => ConsistencyStatus::Ahead {
                expected_index: expected_log_index,
                actual_index,
            },
        };

        // If inconsistent, increment violation count
        if status != ConsistencyStatus::Consistent {
            let mut metadata = self.metadata.write().await;
            metadata.violation_count += 1;

            log::warn!(
                "Node {} consistency violation detected: {:?}",
                self.node_id,
                status
            );
        }

        Ok(status)
    }

    /// Perform deep consistency check by verifying data integrity
    pub async fn deep_consistency_check(&self) -> RaftResult<ConsistencyStatus> {
        // Check for data corruption by iterating through all keys
        let iter = self.engine.iterator(IteratorMode::Start);
        let mut key_count = 0;
        let mut corruption_detected = false;
        let mut corruption_reason = String::new();

        for item in iter {
            match item {
                Ok((key, value)) => {
                    key_count += 1;

                    // Basic sanity checks
                    if key.is_empty() {
                        corruption_detected = true;
                        corruption_reason = "Empty key detected".to_string();
                        break;
                    }

                    // Check for extremely large values that might indicate corruption
                    if value.len() > 100 * 1024 * 1024 {
                        // 100MB threshold
                        corruption_detected = true;
                        corruption_reason = format!(
                            "Suspiciously large value ({} bytes) for key: {:?}",
                            value.len(),
                            String::from_utf8_lossy(&key)
                        );
                        break;
                    }
                }
                Err(e) => {
                    corruption_detected = true;
                    corruption_reason = format!("Iterator error: {}", e);
                    break;
                }
            }
        }

        if corruption_detected {
            let mut metadata = self.metadata.write().await;
            metadata.violation_count += 1;

            log::error!(
                "Node {} data corruption detected: {}",
                self.node_id,
                corruption_reason
            );

            return Ok(ConsistencyStatus::Corrupted {
                reason: corruption_reason,
            });
        }

        log::info!(
            "Node {} deep consistency check passed: {} keys verified",
            self.node_id,
            key_count
        );

        Ok(ConsistencyStatus::Consistent)
    }

    /// Recover from state machine inconsistency
    pub async fn recover_consistency(&self, target_index: LogIndex) -> RaftResult<()> {
        let current_timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();

        log::info!(
            "Node {} starting consistency recovery to index {}",
            self.node_id,
            target_index
        );

        // For now, we'll implement a basic recovery by updating the applied index
        // In a full implementation, this would involve:
        // 1. Requesting missing log entries from the leader
        // 2. Re-applying entries from the last known good state
        // 3. Verifying the recovered state

        self.set_applied_index(target_index).await?;

        // Update recovery metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.last_recovery_timestamp = Some(current_timestamp);
        }

        log::info!(
            "Node {} consistency recovery completed to index {}",
            self.node_id,
            target_index
        );

        Ok(())
    }

    /// Get consistency metadata for monitoring
    pub async fn get_metadata(&self) -> ConsistencyMetadata {
        self.metadata.read().await.clone()
    }

    /// Reset consistency violation count (for testing/maintenance)
    pub async fn reset_violation_count(&self) {
        let mut metadata = self.metadata.write().await;
        metadata.violation_count = 0;
    }

    /// Check if recovery is needed based on consistency status
    pub fn needs_recovery(&self, status: &ConsistencyStatus) -> bool {
        matches!(
            status,
            ConsistencyStatus::Behind { .. }
                | ConsistencyStatus::Ahead { .. }
                | ConsistencyStatus::Corrupted { .. }
        )
    }

    /// Get recovery strategy for a given consistency status
    pub fn get_recovery_strategy(&self, status: &ConsistencyStatus) -> RecoveryStrategy {
        match status {
            ConsistencyStatus::Consistent => RecoveryStrategy::None,
            ConsistencyStatus::Behind { .. } => RecoveryStrategy::ReplayMissingEntries,
            ConsistencyStatus::Ahead { .. } => RecoveryStrategy::RollbackExtraEntries,
            ConsistencyStatus::Corrupted { .. } => RecoveryStrategy::FullStateReconstruction,
        }
    }

    /// Get the current applied index from the state machine
    async fn get_applied_index(&self) -> RaftResult<LogIndex> {
        // In a real implementation, this would read from a special metadata key
        // For now, we'll use a simple approach
        const APPLIED_INDEX_KEY: &[u8] = b"__raft_applied_index__";

        match self.engine.get(APPLIED_INDEX_KEY) {
            Ok(Some(value)) => {
                let index_str = String::from_utf8(value)
                    .map_err(|_| RaftError::state_machine("Invalid applied index format"))?;
                index_str
                    .parse::<LogIndex>()
                    .map_err(|_| RaftError::state_machine("Failed to parse applied index"))
            }
            Ok(None) => Ok(0), // No applied index stored yet
            Err(e) => Err(RaftError::state_machine(format!(
                "Failed to read applied index: {}",
                e
            ))),
        }
    }

    /// Set the applied index in the state machine
    async fn set_applied_index(&self, index: LogIndex) -> RaftResult<()> {
        const APPLIED_INDEX_KEY: &[u8] = b"__raft_applied_index__";

        self.engine
            .put(APPLIED_INDEX_KEY, index.to_string().as_bytes())
            .map_err(|e| RaftError::state_machine(format!("Failed to set applied index: {}", e)))
    }
}

/// Recovery strategy for different consistency violations
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum RecoveryStrategy {
    /// No recovery needed
    None,
    /// Replay missing log entries from the leader
    ReplayMissingEntries,
    /// Rollback extra entries (should rarely happen)
    RollbackExtraEntries,
    /// Full state reconstruction from snapshot
    FullStateReconstruction,
}

/// Consistency monitor for periodic checks
pub struct ConsistencyMonitor {
    checker: Arc<ConsistencyChecker>,
    check_interval_secs: u64,
}

impl ConsistencyMonitor {
    /// Create a new consistency monitor
    pub fn new(checker: Arc<ConsistencyChecker>, check_interval_secs: u64) -> Self {
        Self {
            checker,
            check_interval_secs,
        }
    }

    /// Start periodic consistency monitoring
    pub async fn start_monitoring(&self, expected_log_index: Arc<RwLock<LogIndex>>) {
        let checker = Arc::clone(&self.checker);
        let interval = self.check_interval_secs;

        tokio::spawn(async move {
            let mut interval_timer =
                tokio::time::interval(tokio::time::Duration::from_secs(interval));

            loop {
                interval_timer.tick().await;

                let current_expected_index = *expected_log_index.read().await;

                match checker.verify_consistency(current_expected_index).await {
                    Ok(ConsistencyStatus::Consistent) => {
                        log::debug!("Periodic consistency check passed");
                    }
                    Ok(status) => {
                        log::warn!("Periodic consistency check failed: {:?}", status);

                        if checker.needs_recovery(&status) {
                            if let Err(e) =
                                checker.recover_consistency(current_expected_index).await
                            {
                                log::error!("Consistency recovery failed: {}", e);
                            }
                        }
                    }
                    Err(e) => {
                        log::error!("Consistency check error: {}", e);
                    }
                }
            }
        });
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use engine::RocksdbEngine;
    use rocksdb::{DB, Options};
    use tempfile::TempDir;

    fn create_test_engine() -> (TempDir, Arc<RocksdbEngine>) {
        let temp_dir = TempDir::new().unwrap();
        let mut opts = Options::default();
        opts.create_if_missing(true);
        let db = DB::open(&opts, temp_dir.path()).unwrap();
        let engine = Arc::new(RocksdbEngine::new(db));
        (temp_dir, engine)
    }

    #[tokio::test]
    async fn test_consistency_check_consistent() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine, 1);

        // Set applied index to 5
        checker.set_applied_index(5).await.unwrap();

        // Check consistency with expected index 5
        let status = checker.verify_consistency(5).await.unwrap();
        assert_eq!(status, ConsistencyStatus::Consistent);
    }

    #[tokio::test]
    async fn test_consistency_check_behind() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine, 1);

        // Set applied index to 3
        checker.set_applied_index(3).await.unwrap();

        // Check consistency with expected index 5
        let status = checker.verify_consistency(5).await.unwrap();
        assert_eq!(
            status,
            ConsistencyStatus::Behind {
                expected_index: 5,
                actual_index: 3,
            }
        );
    }

    #[tokio::test]
    async fn test_consistency_check_ahead() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine, 1);

        // Set applied index to 7
        checker.set_applied_index(7).await.unwrap();

        // Check consistency with expected index 5
        let status = checker.verify_consistency(5).await.unwrap();
        assert_eq!(
            status,
            ConsistencyStatus::Ahead {
                expected_index: 5,
                actual_index: 7,
            }
        );
    }

    #[tokio::test]
    async fn test_deep_consistency_check() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine.clone(), 1);

        // Add some test data
        engine.put(b"key1", b"value1").unwrap();
        engine.put(b"key2", b"value2").unwrap();

        let status = checker.deep_consistency_check().await.unwrap();
        assert_eq!(status, ConsistencyStatus::Consistent);
    }

    #[tokio::test]
    async fn test_recovery_strategy() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine, 1);

        let consistent = ConsistencyStatus::Consistent;
        let behind = ConsistencyStatus::Behind {
            expected_index: 5,
            actual_index: 3,
        };
        let ahead = ConsistencyStatus::Ahead {
            expected_index: 3,
            actual_index: 5,
        };
        let corrupted = ConsistencyStatus::Corrupted {
            reason: "test".to_string(),
        };

        assert_eq!(
            checker.get_recovery_strategy(&consistent),
            RecoveryStrategy::None
        );
        assert_eq!(
            checker.get_recovery_strategy(&behind),
            RecoveryStrategy::ReplayMissingEntries
        );
        assert_eq!(
            checker.get_recovery_strategy(&ahead),
            RecoveryStrategy::RollbackExtraEntries
        );
        assert_eq!(
            checker.get_recovery_strategy(&corrupted),
            RecoveryStrategy::FullStateReconstruction
        );
    }

    #[tokio::test]
    async fn test_metadata_tracking() {
        let (_temp_dir, engine) = create_test_engine();
        let checker = ConsistencyChecker::new(engine, 1);

        // Initial metadata should be default
        let metadata = checker.get_metadata().await;
        assert_eq!(metadata.violation_count, 0);

        // Trigger a consistency violation
        checker.set_applied_index(3).await.unwrap();
        checker.verify_consistency(5).await.unwrap();

        // Check that violation count increased
        let metadata = checker.get_metadata().await;
        assert_eq!(metadata.violation_count, 1);

        // Reset violation count
        checker.reset_violation_count().await;
        let metadata = checker.get_metadata().await;
        assert_eq!(metadata.violation_count, 0);
    }
}
